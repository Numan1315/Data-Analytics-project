{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b579702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb479f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"Ratings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86a142ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated(['name','review']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d00c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(['name','review'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfeee3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e08b8d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130618, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01d95fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    83152\n",
       "-1    29359\n",
       " 0    18107\n",
       "Name: rate_pred, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rate_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bc1a305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Analysis</th>\n",
       "      <th>Vader Sentiment</th>\n",
       "      <th>Vader Analysis</th>\n",
       "      <th>rate_pred</th>\n",
       "      <th>rate_pred1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jalsa</td>\n",
       "      <td>4.0</td>\n",
       "      <td>a beautiful place to dine inthe interiors take...</td>\n",
       "      <td>beautiful place dine inthe interior take back ...</td>\n",
       "      <td>0.438624</td>\n",
       "      <td>0.229762</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jalsa</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i was here for dinner with my family on a week...</td>\n",
       "      <td>dinner family weekday restaurant completely em...</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9646</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jalsa</td>\n",
       "      <td>2.0</td>\n",
       "      <td>its a restaurant near to banashankari bda me a...</td>\n",
       "      <td>restaurant near banashankari bda along office ...</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jalsa</td>\n",
       "      <td>4.0</td>\n",
       "      <td>we went here on a weekend and one of us had th...</td>\n",
       "      <td>went weekend one u buffet two u took ala carte...</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jalsa</td>\n",
       "      <td>5.0</td>\n",
       "      <td>the best thing about the place is its ambiance...</td>\n",
       "      <td>best thing place ambiance second best thing yu...</td>\n",
       "      <td>0.368750</td>\n",
       "      <td>0.340625</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9485</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  rating                                             review  \\\n",
       "0  Jalsa     4.0  a beautiful place to dine inthe interiors take...   \n",
       "1  Jalsa     4.0  i was here for dinner with my family on a week...   \n",
       "2  Jalsa     2.0  its a restaurant near to banashankari bda me a...   \n",
       "3  Jalsa     4.0  we went here on a weekend and one of us had th...   \n",
       "4  Jalsa     5.0  the best thing about the place is its ambiance...   \n",
       "\n",
       "                                               Lemma  Subjectivity  Polarity  \\\n",
       "0  beautiful place dine inthe interior take back ...      0.438624  0.229762   \n",
       "1  dinner family weekday restaurant completely em...      0.533333  0.500000   \n",
       "2  restaurant near banashankari bda along office ...      0.566667  0.183333   \n",
       "3  went weekend one u buffet two u took ala carte...      0.655556  0.641667   \n",
       "4  best thing place ambiance second best thing yu...      0.368750  0.340625   \n",
       "\n",
       "   Analysis  Vader Sentiment  Vader Analysis  rate_pred  rate_pred1  \n",
       "0         1           0.7351               1          1           1  \n",
       "1         1           0.9646               1          1           1  \n",
       "2         1           0.7845               1         -1           0  \n",
       "3         1           0.9686               1          1           1  \n",
       "4         1           0.9485               1          1           1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rating(rating):\n",
    "    if(rating > 3):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df['rate_pred1'] = df['rating'].apply(rating) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75002e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    83152\n",
       "0    47466\n",
       "Name: rate_pred1, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rate_pred1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3307053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random split train and test data\n",
    "index = df.index\n",
    "df['random_number'] = np.random.randn(len(index))\n",
    "train = df[df['random_number'] <= 0.70]\n",
    "test = df[df['random_number'] > 0.70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a73aed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99115, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b41805",
   "metadata": {},
   "source": [
    "### Applying CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49370802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 73443)\t1\n",
      "  (0, 678125)\t1\n",
      "  (0, 246993)\t1\n",
      "  (0, 447795)\t1\n",
      "  (0, 447064)\t1\n",
      "  (0, 888301)\t1\n",
      "  (0, 57953)\t1\n",
      "  (0, 573238)\t1\n",
      "  (0, 286853)\t1\n",
      "  (0, 495611)\t1\n",
      "  (0, 667666)\t1\n",
      "  (0, 995514)\t1\n",
      "  (0, 606248)\t1\n",
      "  (0, 163203)\t1\n",
      "  (0, 501447)\t1\n",
      "  (0, 450682)\t1\n",
      "  (0, 50147)\t1\n",
      "  (0, 892591)\t1\n",
      "  (0, 803371)\t1\n",
      "  (0, 185219)\t1\n",
      "  (0, 14226)\t1\n",
      "  (0, 183126)\t1\n",
      "  (0, 107536)\t1\n",
      "  (0, 197254)\t1\n",
      "  (0, 84158)\t1\n",
      "  :\t:\n",
      "  (99114, 196107)\t1\n",
      "  (99114, 170371)\t1\n",
      "  (99114, 707206)\t1\n",
      "  (99114, 627381)\t1\n",
      "  (99114, 458418)\t1\n",
      "  (99114, 686640)\t1\n",
      "  (99114, 18795)\t1\n",
      "  (99114, 84975)\t1\n",
      "  (99114, 827481)\t1\n",
      "  (99114, 649556)\t1\n",
      "  (99114, 502499)\t1\n",
      "  (99114, 565753)\t1\n",
      "  (99114, 276052)\t1\n",
      "  (99114, 670191)\t1\n",
      "  (99114, 374593)\t1\n",
      "  (99114, 84996)\t1\n",
      "  (99114, 750394)\t1\n",
      "  (99114, 614368)\t1\n",
      "  (99114, 670192)\t1\n",
      "  (99114, 649562)\t1\n",
      "  (99114, 757527)\t1\n",
      "  (99114, 538428)\t1\n",
      "  (99114, 458446)\t1\n",
      "  (99114, 541125)\t1\n",
      "  (99114, 170458)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b',ngram_range=(1,2))\n",
    "train_matrix = vectorizer.fit_transform(train['Lemma'])\n",
    "test_matrix = vectorizer.transform(test['Lemma'])\n",
    "print(train_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b1dc1c",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "92f5bc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4d5d34a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_matrix\n",
    "X_test = test_matrix\n",
    "y_train = train['rate_pred1']\n",
    "y_test = test['rate_pred1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "247d3088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ddf6b4",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5ea88fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'LogisticRegression.pkl' \n",
    "with open(filename,'wb') as file:\n",
    "    pickle.dump(lr , file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "053d3ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(filename,'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "loaded_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b6af44ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9101,  1724],\n",
       "       [ 2355, 18323]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "new = np.asarray(y_test)\n",
    "confusion_matrix(predictions,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7e16bbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82     10825\n",
      "           1       0.91      0.89      0.90     20678\n",
      "\n",
      "    accuracy                           0.87     31503\n",
      "   macro avg       0.85      0.86      0.86     31503\n",
      "weighted avg       0.87      0.87      0.87     31503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c610653b",
   "metadata": {},
   "source": [
    "### Accuracy Obtained from Logistic Regression 0.87 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69341df",
   "metadata": {},
   "source": [
    "### MultinomialNB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c9ec03ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import  MultinomialNB\n",
    "nb_clf = MultinomialNB()\n",
    "from sklearn.metrics import classification_report\n",
    "parameters = {  \n",
    "'alpha': (1, 0.1, 0.01, 0.001, 0.0001, 0.00001)  \n",
    "}  \n",
    "clf = GridSearchCV(nb_clf, parameters, cv=10, scoring='neg_root_mean_squared_error')\n",
    "grid_result=clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3da1859b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.37764526337683735 {'alpha': 1}\n"
     ]
    }
   ],
   "source": [
    "print(grid_result.best_score_,grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a6eee820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'MultinomialNB.sav'\n",
    "pickle.dump(clf , open(filename,'wb'))\n",
    "##load the model\n",
    "loaded_model = pickle.load(open(filename,'rb'))\n",
    "result = loaded_model.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6bcf94e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3808747160324033\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9045    0.6720    0.7711     11456\n",
      "           1     0.8366    0.9594    0.8938     20047\n",
      "\n",
      "    accuracy                         0.8549     31503\n",
      "   macro avg     0.8705    0.8157    0.8325     31503\n",
      "weighted avg     0.8613    0.8549    0.8492     31503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result)\n",
    "print(classification_report(y_test, grid_result.predict(X_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "870ff7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8962    0.2117    0.3425     11456\n",
      "           1     0.6864    0.9860    0.8094     20047\n",
      "\n",
      "    accuracy                         0.7044     31503\n",
      "   macro avg     0.7913    0.5988    0.5759     31503\n",
      "weighted avg     0.7627    0.7044    0.6396     31503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree = DecisionTreeClassifier(max_depth=3)\n",
    "decision_tree = decision_tree.fit(X_train,y_train)\n",
    "print(classification_report(y_test, decision_tree.predict(X_test), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb529bc1",
   "metadata": {},
   "source": [
    "### Accuracy Obtained from MultinomialNB 0.70"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0fd4b7",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40716152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(max_depth = 3).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80ba0e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000     11456\n",
      "           1     0.6364    1.0000    0.7778     20047\n",
      "\n",
      "    accuracy                         0.6364     31503\n",
      "   macro avg     0.3182    0.5000    0.3889     31503\n",
      "weighted avg     0.4049    0.6364    0.4949     31503\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, classifier.predict(X_test), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63227cf",
   "metadata": {},
   "source": [
    "### Accuracy Obtained from Random Forest Classifier 0.63"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44db2f95",
   "metadata": {},
   "source": [
    "### Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbdbda9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7727    0.7382    0.7551     11456\n",
      "           1     0.8541    0.8759    0.8649     20047\n",
      "\n",
      "    accuracy                         0.8258     31503\n",
      "   macro avg     0.8134    0.8071    0.8100     31503\n",
      "weighted avg     0.8245    0.8258    0.8249     31503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abc = AdaBoostClassifier()\n",
    "abc = abc.fit(X_train,y_train)\n",
    "print(classification_report(y_test, abc.predict(X_test), digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551e2a32",
   "metadata": {},
   "source": [
    "### Accuracy Obtained from Adaboost Classifier 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eff0cd4",
   "metadata": {},
   "source": [
    "### Long-Short Term Memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d84665bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.7.0-cp38-cp38-win_amd64.whl (430.8 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.41.1-cp38-cp38-win_amd64.whl (3.2 MB)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "Collecting gast<0.5.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
      "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.19.1-cp38-cp38-win_amd64.whl (895 kB)\n",
      "Collecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Collecting libclang>=9.0.1\n",
      "  Downloading libclang-12.0.0-py2.py3-none-win_amd64.whl (13.1 MB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.21.0\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.21.0-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Collecting keras<2.8,>=2.7.0rc0\n",
      "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Collecting flatbuffers<3.0,>=1.12\n",
      "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.3.3-py2.py3-none-any.whl (155 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=971c35eed0ed955f500877f1b0acfe989cbfe07aa31cb503aaca7fefd9d69adc\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-0.15.0 astunparse-1.6.3 cachetools-4.2.4 flatbuffers-2.0 gast-0.4.0 google-auth-2.3.3 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.41.1 keras-2.7.0 keras-preprocessing-1.1.2 libclang-12.0.0 markdown-3.3.4 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.19.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0 tensorflow-io-gcs-filesystem-0.21.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "abb5e638",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split       # for splitting dataset\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  # to encode text to int\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences   # to do padding or truncating\n",
    "from tensorflow.keras.models import Sequential     # the model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense # layers of the architecture\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint   # save model\n",
    "from tensorflow.keras.models import load_model   # load saved model\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1a2d3b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93026     hi first experience smoke ben highly recommend...\n",
      "37663     ancient place nostalgia strike every time go l...\n",
      "27868     one worst experience ever waiter deny one orde...\n",
      "73298     wanted try waffle sandwich chose sin waffle bw...\n",
      "55761     one favorite place dine dahi ke kebab die grea...\n",
      "                                ...                        \n",
      "30536     good food great service quality product custom...\n",
      "57279     celebrate birthday place really nice polite st...\n",
      "120629                 received rubber band gobi manchurian\n",
      "73057     even thought delivered late im giving four sta...\n",
      "79609     one good outlet behrouz biryani best biryani s...\n",
      "Name: Lemma, Length: 104494, dtype: object \n",
      "\n",
      "109406    visited many place ab barbeque nation many bbq...\n",
      "44060     ordered konaseema chicken starter aandhrautton...\n",
      "42166                                     good quality food\n",
      "51481                                         late delivery\n",
      "6328      ordered paneer bhurji poha packing really nice...\n",
      "                                ...                        \n",
      "70846     favorite cafe bangalore ambience rightly captu...\n",
      "17005     saturday night well spent iceland jayanagar fr...\n",
      "43178     one pocket friendly restraunt kundanhalli area...\n",
      "129688                                           much spice\n",
      "39698     place nice bring friend family enjoy ice cream...\n",
      "Name: Lemma, Length: 26124, dtype: object \n",
      "\n",
      "Test Set\n",
      "93026     1\n",
      "37663     1\n",
      "27868     0\n",
      "73298     1\n",
      "55761     1\n",
      "         ..\n",
      "30536     1\n",
      "57279     1\n",
      "120629    0\n",
      "73057     1\n",
      "79609     1\n",
      "Name: rate_pred1, Length: 104494, dtype: int64 \n",
      "\n",
      "109406    1\n",
      "44060     1\n",
      "42166     0\n",
      "51481     1\n",
      "6328      1\n",
      "         ..\n",
      "70846     1\n",
      "17005     1\n",
      "43178     1\n",
      "129688    0\n",
      "39698     0\n",
      "Name: rate_pred1, Length: 26124, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df['Lemma'], df['rate_pred1'], test_size = 0.2)\n",
    "#print('Train Set')\n",
    "print(x_train, '\\n')\n",
    "print(x_test, '\\n')\n",
    "print('Test Set')\n",
    "print(y_train, '\\n')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "15ca1be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_length():\n",
    "    review_length = []\n",
    "    for review in x_train:\n",
    "        review_length.append(len(review))\n",
    "\n",
    "    return int(np.ceil(np.mean(review_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3cba18d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded X Train\n",
      " [[1485   98   33 ... 1165    1    0]\n",
      " [7333    3 3760 ...   21    0    0]\n",
      " [   8  119   33 ...    0    0    0]\n",
      " ...\n",
      " [ 491 2220 2668 ...    0    0    0]\n",
      " [  43  408  141 ...    0    0    0]\n",
      " [   8    2  121 ...    0    0    0]] \n",
      "\n",
      "Encoded X Test\n",
      " [[ 118  138    3 ...   32  254 1788]\n",
      " [   7 4437    4 ...    0    0    0]\n",
      " [   2   27    1 ...    0    0    0]\n",
      " ...\n",
      " [   8  168   56 ...    0    0    0]\n",
      " [  50  277    0 ...    0    0    0]\n",
      " [   3   18 1107 ...    0    0    0]] \n",
      "\n",
      "Maximum review length:  29\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ENCODE REVIEW\n",
    "token = Tokenizer(lower=False)    # no need lower, because already lowered the data in load_data()\n",
    "token.fit_on_texts(x_train)\n",
    "x_train = token.texts_to_sequences(x_train)\n",
    "x_test = token.texts_to_sequences(x_test)\n",
    "\n",
    "max_length = get_max_length()\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
    "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n",
    "\n",
    "print('Encoded X Train\\n', x_train, '\\n')\n",
    "print('Encoded X Test\\n', x_test, '\\n')\n",
    "print('Maximum review length: ', max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6a15f8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "510a4351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 29, 32)            2347008   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                24832     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,371,905\n",
      "Trainable params: 2,371,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "EMBED_DIM = 32\n",
    "LSTM_OUT = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n",
    "model.add(LSTM(LSTM_OUT))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d4c1f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'models/LSTM.h5',\n",
    "    monitor='accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5d45a4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "817/817 [==============================] - ETA: 0s - loss: 0.3717 - accuracy: 0.8364\n",
      "Epoch 00001: accuracy improved from -inf to 0.83635, saving model to models\\LSTM.h5\n",
      "817/817 [==============================] - 52s 62ms/step - loss: 0.3717 - accuracy: 0.8364\n",
      "Epoch 2/5\n",
      "817/817 [==============================] - ETA: 0s - loss: 0.2914 - accuracy: 0.8776\n",
      "Epoch 00002: accuracy improved from 0.83635 to 0.87765, saving model to models\\LSTM.h5\n",
      "817/817 [==============================] - 52s 64ms/step - loss: 0.2914 - accuracy: 0.8776\n",
      "Epoch 3/5\n",
      "816/817 [============================>.] - ETA: 0s - loss: 0.2542 - accuracy: 0.8926\n",
      "Epoch 00003: accuracy improved from 0.87765 to 0.89261, saving model to models\\LSTM.h5\n",
      "817/817 [==============================] - 52s 63ms/step - loss: 0.2542 - accuracy: 0.8926\n",
      "Epoch 4/5\n",
      "816/817 [============================>.] - ETA: 0s - loss: 0.2224 - accuracy: 0.9052\n",
      "Epoch 00004: accuracy improved from 0.89261 to 0.90517, saving model to models\\LSTM.h5\n",
      "817/817 [==============================] - 52s 64ms/step - loss: 0.2224 - accuracy: 0.9052\n",
      "Epoch 5/5\n",
      "816/817 [============================>.] - ETA: 0s - loss: 0.1949 - accuracy: 0.9160\n",
      "Epoch 00005: accuracy improved from 0.90517 to 0.91598, saving model to models\\LSTM.h5\n",
      "817/817 [==============================] - 53s 65ms/step - loss: 0.1949 - accuracy: 0.9160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x130913d9280>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size = 128, epochs = 5, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "93768000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Prediction: 22067\n",
      "Wrong Prediction: 4057\n",
      "Accuracy: 84.4702189557495\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test, batch_size = 128)\n",
    "\n",
    "true = 0\n",
    "for i, y in enumerate(y_test):\n",
    "#    print(round(y_pred[i][0]))\n",
    "     if y == (round(y_pred[i][0])):\n",
    "         true += 1\n",
    "\n",
    "print('Correct Prediction: {}'.format(true))\n",
    "print('Wrong Prediction: {}'.format(len(y_pred) - true))\n",
    "print('Accuracy: {}'.format(true/len(y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627b8efe",
   "metadata": {},
   "source": [
    "### Accuracy Obtained from LSTM 0.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "af7b56b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "817/817 [==============================] - 8s 9ms/step - loss: 0.4515 - accuracy: 0.8447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4515098035335541, 0.8447021842002869]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89cd4d3",
   "metadata": {},
   "source": [
    "### LSTM model,logistic regression, multinomialNB performs better than others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c2d2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
